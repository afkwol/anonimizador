lm_api:
  base_url: "http://127.0.0.1:1234/v1"
  api_key: "lm-studio"
  model: "granite-3.1-8b-instruct"

chunking:
  max_prompt_tokens: 3500
  overlap_tokens: 20
  safety_factor: 0.85
  tokenizer: "simple"

inference:
  temperature: 0.0
  top_p: 1.0
  top_k: 1
  max_tokens: 1024
  repeat_penalty: 1.0
  stop_sequences:
    - "</s>"

runtime:
  logs_dir: "logs"
  debug: false
  max_retries: 2
  retry_backoff_seconds: 2.0
  abort_on_failure: false

privacy:
  strict_mode: false
  debug_logs: false
  enable_diff: false
  artifact_ttl_days: 7

pii:
  regex_profiles:
    - "default"
