# Configuraci√≥n del API OpenAI-compatible (LM Studio, Ollama, etc.)
# Para LM Studio, el base URL por defecto es http://127.0.0.1:1234/v1
OPENAI_API_BASE=http://127.0.0.1:1234/v1
OPENAI_API_KEY=lm-studio

# Modelo a utilizar (debe estar cargado en LM Studio)
# Ejemplos: granite-3.1-8b-instruct, llama-3-8b-instruct, etc.
OPENAI_MODEL=granite-3.1-8b-instruct

# Puerto del servidor FastAPI
PORT=8000

# Modo debug (true/false)
DEBUG=false
